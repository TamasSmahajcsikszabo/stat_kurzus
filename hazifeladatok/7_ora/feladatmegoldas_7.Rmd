---
title: "Házi feladatok megoldása 7."
subtitle: "Hierarchikus klaszterelemzés SPSS-ben és R-ben"
csl: apa7.csl
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

Smahajcsik-Szabó Tamás, M9IJYM



```{r echo=FALSE}
# importing C++ code, R libraries and data
options(warn=-1)
#setwd('/home/tamas/repos/stat_kurzus/hazifeladatok/7_ora')
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
#suppressMessages(source("../../src/functions.R"))
#suppressMessages(source("../../src/mad.R"))
suppressMessages(library(readr))
suppressMessages(library(ggrepel))
suppressMessages(library(tidyverse))
suppressMessages(library(effsize))
suppressMessages(library(AICcmodavg))
suppressMessages(library(broom))
suppressMessages(library(confreq))
suppressMessages(library(stringr))
suppressMessages(library(kableExtra))
suppressMessages(library(caret))
suppressMessages(library(tidyverse))
suppressMessages(library(dendextend))
suppressMessages(library(ggdendro))
suppressMessages(library(stats))
suppressMessages(dataset <- read_csv("../../data/data.csv"))
# suppressMessages(labels <- read_csv('../../data/labels.csv'))
```

### 1. Végezz HKA-t SPSS-ben a minimális távolság módszerrel, SED távolsággal a PTELJ, Pboldog, Pmagány input változókkal, outlier kiszűréssel, standardizálással! Hány klaszteres megoldás tűnik a legjobbnak az Agglomeration Schedule Coefficients oszlopának grafikus ábrázolása alapján? És a jégcsapdiagram alapján? És a dendrogram alapján?

Az SPSS *Agglomeration Schedule* táblázatának utolsó sorait az alábbi táblázatba foglaltam.

```{r echo = FALSE}
result1 <- read_delim("SPSS/1.csv", delim = ";")

knitr::kable(tail(result1[,names(result1) %in% c("k", "EESS", "d")], 15), "simple")
```

*k=klaszterszám, EESS%, d=EESS% csökkenés*


Az eredményekről az alábbi könyökábra is tájékoztat. K=10 megoldás esetén az EESS % értékének csökkenése elsőként éri el a 4%-ot, de ez értéke egészen k=2-ig nem ér el 5-6%-nál nagyobb csökkenést.
Végül a *d* (itt a különbözetet jelöltem így) értéke 55% k = 3 után.

Noha az *icile* diagram áttekinthetősége csökkent a nagy esetszám mellett, a dendogram már inkább volt a segítségemre. 
A nagyobb klaszterösszevonásokra viszonylag az iterációk végén került sor, a dendogram nem mutatja az elvárt összevonási mintázatot, feltételezem, a minimális távolság módszere szuboptimális az adott adatokon.


```{r echo = FALSE, fig.width=6, fig.height=4}

crit <- 0.03
plot_data <- result1


ggplot() +
  geom_path(data=plot_data, aes(Stage, EESS)) +
  geom_point(data=plot_data[plot_data$d> crit,], aes(Stage, EESS), size = 4) +
  geom_point(data=plot_data[plot_data$d> crit,], aes(Stage, EESS), size = 3, color = "white") +
  geom_text(data=plot_data[plot_data$d> crit,], aes(Stage, EESS, label = paste0("k = ", k, "; d = ", d * 100, "%")), size = 4, hjust = 1.4) +
  theme_light() +
  labs(
    title = "Hierarchikus klaszterelemzés eredménye minimális távolság módszere \n és SED mellett",
    subtitle = paste0("A pontokkal a nagyobb mint ", crit*100, "% EESS-csökkenést hozó töréspontokat jelölöm"),
    x = "Klaszterösszevonás iterációja (SPSS: Stage)",
    y = "EESS %"
  )

```


### 2. Végezz HKA-t SPSS-ben a Ward módszerrel, SED távolsággal a PTELJ, Pboldog, Pmagány input változókkal, outlier kiszűréssel, standardizálással! Hány klaszteres megoldás tűnik a legjobbnak az Agglomeration Schedule Coefficients oszlopának grafikus ábrázolása alapján? És a jégcsapdiagram alapján? És a dendrogram alapján?

Elsőként az SPSS *Agglomeration Schedule* táblázatának utolsó sorait közlöm.

```{r echo = FALSE}
result2 <- read_delim("SPSS/2.csv", delim = ";")

knitr::kable(tail(result2[,names(result2) %in% c("k", "EESS", "d")], 15), "simple")
```

*k=klaszterszám, EESS%, d=EESS% csökkenés*

Hasonló grafikát képeztem Ward módszerének kiértékelésére, mint fentebb.

```{r echo = FALSE, fig.width=6, fig.height=5}
crit <- 0.02
plot_data <- result2 


ggplot() +
  geom_path(data=plot_data, aes(Stage, EESS)) +
  geom_point(data=plot_data[plot_data$d> crit,], aes(Stage, EESS), size = 4) +
  geom_point(data=plot_data[plot_data$d> crit,], aes(Stage, EESS), size = 3, color = "white") +
  geom_text(data=plot_data[plot_data$d> crit,], aes(Stage, EESS, label = paste0("k = ", k, "; d = ", d * 100, "%")), size = 4, hjust = 1.4) +
  theme_light() +
  labs(
    title = "Hierarchikus klaszterelemzés eredménye minimális távolság módszere \n és SED mellett",
    subtitle = paste0("A pontokkal a nagyobb mint ", crit*100, "% EESS-csökkenést hozó töréspontokat jelölöm"),
    x = "Klaszterösszevonás iterációja (SPSS: Stage)",
    y = "EESS %"
  )
```

Az eredmények alapján egy stabil két klaszteres megoldás rajzolódik ki, de a stabilitás lentebbi tesztelése nyomán k=7, illetve k= 8 is megfelelő lehet.

### 3. Mekkora az előző feladat 5-klaszteres megoldásában EESS% értéke? Vesd össze ezt a ROPstat hasonló elemzésében kapott értékkel (6. óra/7. feladat)!

5 klaszteres megoldás esetén az EESS% `r result2[result2$k ==5, ]$EESS  * 100`%. 
A ROPStat megoldása EESS% = 69.89% volt.

### 4. Végezz HKA-t R-ben a minimális távolság módszerrel, SED távolsággal a PTELJ, Pboldog, Pmagány input változókkal, outlier kiszűréssel, standardizálással! Hány klaszteres megoldás tűnik a legjobbnak a dendrogram alapján?  És az 5.22. ábra szerint elvégzett elemzés grafikonja alapján?

A dendogram minimális távolság módszere mellett nagyon hasonló eredményt hoz mint az SPSS megoldása. 
Jól láthatóan a klaszterképzés eseti, azaz nem nagyobb homogénebb csoportok kialakítása zajlik.
A minimális távolság módszerének megfelelősége vetődik fel.

```{r echo=FALSE, warning=FALSE, fig.width = 8}

dataset <- dataset[,names(dataset) %in% c("PMagány", "PBoldog", "PTelj")]
dataset_scaled <- scale(dataset)
d <- dist(dataset_scaled, method="euclidean")
clustering <- hclust(d, method="single")
dhc <- as.dendrogram(clustering)
ddata <- dendro_data(dhc, type = "rectangle")
ggplot(segment(ddata)) + 
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend), alpha = 1/3) + 
  geom_point(aes(x,y), color="black", alpha = 1/2, shape=1, size = 0.25) +
  labs(
       title = "Dendrogram: HKA a minimális távolság módszerével",
       x = "",
       y = "Height"
  ) +
  theme_light()
```

A könyök teszt hasonlóképp nem egyértelmű k=15 alatt, a Silhouett Index k=2-t valószínűsít.

```{r echo=FALSE, warning=FALSE, fig.width=8}
library(ggplot2)
library(factoextra)
library(stats)
p1 <- fviz_nbclust(dataset_scaled, FUN = hcut, method = "wss", k.max = 15) +
ggtitle("Könyökteszt") 
p2 <- fviz_nbclust(dataset_scaled, FUN = hcut, method = "silhouette", k.max = 15) +
ggtitle("Silhouette index") 
gridExtra::grid.arrange(p1, p2, nrow = 1) 


```

A kettőtől tizenötig terjedő klaszteres megoldások további tesztelésére az *fpc* R csomag *clusterboost* függvényét használtam. 
Ez a funckió alapesetben B=100 bootstrap újramintázással teszteli az adott klaszterstruktúra stabilitását, azaz számon tartja, a korábbi iterációban képzett klaszter megmarad-e, vagy feloszlik-e az újabb iteráció során. 
Az alábbiakban a stabilitási indexre [0 és 1 között], illetve a feloszlások számára közlöm az eredményeket.

A Silhouette index alapján kínált k=2 megoldás elemzése során azt találjuk 100 esetből 40 alkalommal nem volt megismételhető egy stabil második klaszter. Mint az első feladat megoldásánál, itt is a minimális távolság nem megfelelőségében látom a klaszterstruktúra nem illeszedésének okát.

```{r echo=FALSE, warning=FALSE}
library(fpc)
kbest.p <- 2
cboot.clust2 <- readRDS("cboot2.RDS")
solution2_stab <- round(cboot.clust2$bootmean, 4)
solution2_dissolved <-cboot.clust2$bootbrd


solution2 <- tibble(
  k = c(1,2),
  stabilitás = solution2_stab,
  `feloszlások száma` = solution2_dissolved
)
knitr::kable(solution2, "simple")
```


Az alábbi ábrán a k=3 és k=15 közti klaszterstruktúra stabilitását mutatom be.
Az első klaszter teljesen stabil, apró vonalka jelzi, hogy 0 a feloszlások száma.
A többi esetben 30 és 60 között ingadozik a feloszlások száma 100 futásból, a *k* értéke mentén váltazkozva. 
Ennek alapján a minimális távolság arra tereli a figyelmet, hogy más módszer lenne megfelelő valós struktúrák kinyerésére a kérdéses három változó esetén.

```{r echo=FALSE, warning=FALSE, fig.width=10, fig.height=8, warning=FALSE}
solution15  <- readRDS("cboot_single15.RDS") 
ggplot(solution15) +
    geom_col(aes(k, `feloszlások száma`), color="black", fill="white") +
    facet_wrap(~k_total) +
    theme_light() +
    labs(
         title = "Klaszterstabilitás k=3 és k=15 között (minimális távolság)",
         x = "k, klaszterek száma",
         y = "Klaszterfeloszlások száma az iterációk során",
         caption = "boostrap B=100, random seed = 1848"
    )

```

### 5. Végezz HKA-t R-ben a Ward módszerrel, SED távolsággal a PTELJ, Pboldog, Pmagány input változókkal, outlier kiszűréssel, standardizálással! Hány klaszteres megoldás tűnik a legjobbnak a dendrogram alapján? És az 5.22. ábra szerint elvégzett elemzés grafikonja alapján?

Az alábbi dendogram alalpján a k=2 ,k=7, illetve k=8 megoldások tűnnek megfelelőnek. 
Ez a Silhouette index adta k=2 megoldás is erősíti.


```{r echo=FALSE, warning=FALSE, fig.width=10, fig.height=6}
clustering_ward <- hclust(d, method="ward.D2")
dhc <- as.dendrogram(clustering_ward)
ddata <- dendro_data(dhc, type = "rectangle")
ggplot(segment(ddata)) + 
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend), alpha = 1/3) + 
  geom_point(aes(x,y), color="black", alpha = 1/2, shape=1, size = 0.25) +
  labs(
       title = "Dendrogram: HKA Ward módszerével",
       x = "",
       y = "Height"
  ) +
  theme_light()
```

Alább táblázatosan összegzem a stabilitást Ward módszerével.


```{r echo=FALSE, warning=FALSE}
criteria <- 0.7
ward_stability <- readRDS("ward_stability.RDS")
summary <- ward_stability %>%
  mutate(check = stabilitás >= criteria) %>%
  group_by(k = k_total) %>%
  summarise(`stabil klaszterek aránya` = round(sum(check)/k, 3),
              `átlagos klaszterstabilitás` = round(mean(stabilitás),3),
              `minimum klaszterstabilits` = round(min(stabilitás),3),
              `maximum klaszterstabilitás` = round(max(stabilitás),3)) %>%
  unique()
knitr::kable(summary, 'simple')
```

Ha grafikusan tekintjük a stabilitást (lásd az alábbi diagrammot), noha a feloszlások száma magasabb is mint 60 nem egy esetben (a minimális távolsággal összevetésben), ugyanakkor több olyan klaszterstruktúra is képződött, ahol nem egy klaszter stabilitása magasabb volt (a feloszlások száma <30).
Mindez, illetve a dendogram alapján a Ward egy megfelelőbb módszernek tűnik a klaszterstruktúra feltárására az adott adatokon.

```{r echo=FALSE, warning=FALSE, fig.width=10, fig.height=8, warning=FALSE}
ggplot(ward_stability) +
    geom_col(aes(k, `feloszlások száma`), color="black", fill="white") +
    facet_wrap(~k_total) +
    theme_light() +
    labs(
         title = "Klaszterstabilitás k=2 és k=15 között (Ward)",
         x = "k, klaszterek száma",
         y = "Klaszterfeloszlások száma az iterációk során",
         caption = "boostrap B=100"
    )

```

### 6. Mentsd el az előző feladat 5-klaszteres megoldását, másold be ROPstatba és ott a Validálás modul segítségével számítsd ki a főbb QC mutatókat! Vesd össze ezt a ROPstat hasonló elemzésében kapott értékekkel (6. óra/7. feladat)!

Az alábbi táblázat tartalmazza a főbb mutatókat a ROPStat és az R megoldásaiból. A két rendszer nagyon hasonló melgoldásokra jutott. A legnagyobb eltérést a módosított Xien-Beni indexben találtam.

```{r echo=FALSE, warning=FALSE}
clusters <- tibble(clust = cutree(clustering_ward, k=5))
dataset_clusters <- bind_cols(dataset, clusters)
#write_csv(dataset_clusters, "dataset_clusters.csv")

qc <- read_delim("QC.csv", delim=";")
qc <- qc[,c(-6, -7, -9)]

knitr::kable(
  tibble(
    QC = names(qc),
    ROPStat = unname(unlist(qc[2,])),
    R = unname(unlist(qc[1,]))
  ),
  "simple"
)


```

